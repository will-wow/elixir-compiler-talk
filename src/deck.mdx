import { Notes, Invert, Head } from "mdx-deck";
import { Flex, Box, Heading } from "theme-ui";
import { CodeSurfer } from "code-surfer";
import "prismjs/components/prism-elixir";

import BgImage from "./components/BgImage";
import Img from "./components/Img";

import deckTheme from "./theme";

import nand2tetris from "./assets/nand2tetris.webp";
import jim from "./assets/jim.jpg";
import ast from "./assets/ast.png";
import astIf from "./assets/ast-if.png";

export const theme = deckTheme;

<Head>

<title>Compiler in Elixir</title>

</Head>

# Writing a compiler in Elixir

<Img alt="nand2tetris logo" src={nand2tetris} />

## Will Ockelmann-Wagner

will@ae.studio | [github.com/will-wow](http://github.com/will-wow)

<Notes>

Hi, me, AE

</Notes>

---

# Elixir: What is it good for?

- High concurrency
- Low Processing
- Updates in the field
- High Uptime
- Developer Happiness

<Notes>

- Anyone in the Elixir community can rattle off the best use case for Elixir
- Anything a phone switch can do
- So long story short, I used Elixir for something completely different, and it went great!

</Notes>

---

# Compilers, what are they about?

| Feature              | Elixir | Compilers     |
| -------------------- | ------ | ------------- |
| Concurrency          | Yes    | Not this time |
| Processing           | Light  | Heavy         |
| Uptime               | High   | Crash         |
| Updates in the field | Yes    | No            |
| Developer Happiness  | Yes    | **Yes!**      |

<Notes>

- A compiler can make good use of concurrency, but mine doesn't
- Elixir isn't at its best when doing CPU-intensive processing, and that's all a compiler is
- Elixir is good at never crashing, and a compiler should crash as soon as it hits an error
- And Field updates aren't relevant to a local tool
- But the developer experience is still great, so I decided to do it anyway

</Notes>

---

# One more problem with my plan...

---

<BgImage src={jim} backgroundColor={theme.colors.background} />

<Notes>

- I mostly write web apps, not compilers
- So first of all, I'm sure there are better ways of doing some of the things we're going to see
- But, why did I write one at all

</Notes>

---

# Nand2Tetris

<Img alt="nand2tetris logo" src={nand2tetris} />

[nand2tetris.org](https://www.nand2tetris.org)

<Notes>

- Let's talk about Nand2Tetris. Anyone here familar with it?
- My degree's in econ not CS, and while that's worked out fine
- I've never really understood how computers, like, work?
- A coworker of mine at C5 suggested and ran this class called Nand2Tetris to help with that

</Notes>

---

# Nand2Tetris

- Design logic gates
- Design CPU & Memory
- Write machine code
- Build assembler for Assembly => Machine Code
- Build VM Translator for Bytecode => Assembly
- Build Compiler from Code => Bytecode
- Build OS
- Write, compile, and run software!

<Notes>

- Talk through steps
- bytecode is like Beam files

</Notes>

---

# I know what an array is now!

<Notes>

- I know what an array is now! Like _really_ know
- Would recommend
- a couple months
- the Coursera class is good and free

</Notes>

---

# Suggested language: Java :-1:

- Assembler
- VM Translator
- Compiler

<Notes>

- For the three text processing tools, they suggest Java or Python.

</Notes>

---

# Elixir :+1:

<Notes>

- But that's lame, I wanted to write them in Elixir!
- So that's what I did.

</Notes>

---

# Topics

- Nand2Tetris
- Tokenizer
- Abstract Syntax Tree
- Unique numbers
- Elixir CLI Tool
- Error Handling

<Notes>

- It's a big project, but there are a few interesting pieces to talk about
- First we'll talk quickly about how a compiler works
- Then we'll see how to set up a CLI tool with Elixir
- Then, we'll see how the File streaming facility in Elixir was really useful here
- Talk about designing and consuming an AST
- How how's Elixir has a facility for unique numbers that was helpful
- And finally See custom error handling for a better development experience
- That's a lot of stuff, but we'll go over these quickly to give you a taste of these helpful tools and techniques

</Notes>

---

# Topics

- **Nand2Tetris**
- Tokenizer
- Abstract Syntax Tree
- Unique numbers
- Error Handling

<Notes>

- So compilers, how do they work?

</Notes>

---

<CodeSurfer>

```javascript title="Jack"
/**
 * A person
 */
class Person {
  field int birthYear;

  constructor Person new(int year) {
    birthYear = year;
    return this;
  }

  method boolean isAdult(int year) {
    var int age;

    // Calculate age
    let age = year - birthYear;

    return age > 17;
  }
}
```

</CodeSurfer>

<Notes>

- First it's helpful to see what we'll be compiling!
- The course takes you through the design of a high-level object oriented language called Jack.
- It's similar to Java, with comments, classes, objects, methods, control structures, attributes, and operators.
- Designed to be simple and easy to compile, but full-featured enough to be interesting

</Notes>

---

<CodeSurfer>

```elixir title="Compiler"
filename
|> File.stream!()
|> Tokens.tokenize()
|> Parser.run(filename)
|> Engine.run(filename)
```

```diff 1:2

```

```diff 3

```

```diff 4

```

```diff 5

```

</CodeSurfer>

<Notes>

- To compile that code into VM code takes a few steps.
- First we use Elixir's File.stream to get an enumerable stream of strings from the source file, one at a time
- a tokenizer converts that into a more useful list of tokens like 17 or "less than"
- a parser converts the tokens into an AST, which we'll see more of soon
- and finally the engine converts the AST into a list of VM commands, which a VM translator can translate into assembly for a target platform like x86
- or in the case of nand2tetris, the Hack computer they have you design from the ground up
- So as you can see, this is just a functional pipeline that takes a list of strings and converts it though multiple steps to another list of strings
- That means a functional language like Elixir is going to work really well, because these are (more or less) pure functions

</Notes>

---

<CodeSurfer>

```elixir
test "tokenizes an expression" do
  assert Tokenizer.run(["x + (y * 512)"]) ==
            [
              %Identifier{value: "x"},
              %Symbol{value: "+"},
              %Symbol{value: "("},
              %Identifier{value: "y"},
              %Symbol{value: "*"},
              %IntegerConstant{value: 512},
              %Symbol{value: ")"}
            ]
end
```

```diff 2[26:38]

```

```diff 4:10

```

</CodeSurfer>

<Notes>

- The tokenizer breaks a string of code like x + y \* 512 into a list of tokens that describe numbers, variables, parens, whatever
- Because this is Elixir, the best way to represent those tokens is as structs
- That way later pattern match and make decisions
- And you can see that this makes the tokenizer great to test, because it's just functions and structs, it doesn't need to know about files or streams or anything like that

</Notes>

---

# How to write an Elixir tokenizer?

---

# Recursion!

---

<CodeSurfer>

```elixir
def process([char | chars], tokens) do
  [next | next_chars] = chars

  cond do
    # Comment
    {char, next} == {"/", "*"} ->
      chars = process_comment(next_chars)
      process(chars, tokens)

    # String
    char == "\"" ->
      {chars, token} = process_string(chars)
      process(chars, [token | tokens])

    # Symbols
    Enum.member?(@symbols, char) ->
      tokens = [Token.Symbol.new(char) | tokens]
      process(chars, tokens)

    # Integers
    Regex.match?(@integer, char) ->
      {chars, token} = process_integer(chars)
      process(chars, [token | tokens])

    # Identifiers and Keywords
    Enum.member?(@identifier, char) ->
      {chars, token} = process_word(chars, char)
      process(chars, [token | tokens])

    # Ignore whitespace
    Enum.member?(@whitespace, char) ->
      process(chars, tokens)
  end
end
```

```diff 6:8

```

```diff 11:13

```

```diff 21:23

```

</CodeSurfer>

<Notes>

- The core of the tokenizer is this recursive function. It takes a look at the next two characters
- enough to always know the next token
- if we see slash start, throw away chars until we hit start slash
- if we see a quote, collect chars into a string until we see another quote
- if we see an integer, collect numbers until we hit whitespace or a symbol
- and so on
- the process functions consume return a new token and a list of characters they didn't consume.
- add the token to the accumulator, and then we continue to process the remaining characters
- add in some error handling and other niceties, and you've got yourself a purely functional tokenizer!

</Notes>

---

# Tokenizers

- Config files
- User formulas
- Syntax highlighters
- Linters

<Notes>

- This specific tokenizer is just for fun. But once you know how to build a tokenizer, it can be a powerful tool
- The next time to want to process a config file, or take in an excel-style formula from a user, or contribute to a linter or syntax highlighter, keep this technique in mind!

</Notes>

---

# Abstract Syntax Tree

```javascript
x + y * 512;
```

```elixir
[
  %Identifier{value: "x"},
  %Symbol{value: "+"},
  %Symbol{value: "("},
  %Identifier{value: "y"},
  %Symbol{value: "*"},
  %IntegerConstant{value: 512},
  %Symbol{value: ")"}
]
```

<Notes>

- So now we can turn this code into a list of tokens. But that's not enough to actually do work
- Now we need to transform this arbitrary list of tokens into the understanding that the computer should multiply y by 512, and add x to that
- A great way to encode the understanding, particularly in a language with pattern matching, is an Abstract Syntax Tree, or AST

</Notes>

---

# Abstract Syntax Tree

<Img src={ast} />

<Notes>

- The AST for that formula looks like this
- Every operator takes a left and a right argument. So plus takes x on the left. On the right, it gets the result of passing y and 512 to "times".
- With this, we can go from a bunch of tokens to a nice understanding of what's going on

</Notes>

---

# Abstract Syntax Tree: It can grow!

```javascript
if (x > 10) {
  let x = 10;
} else {
  let x = x + 1;
}
```

<Notes>

- How about something bigger?
- This if statement is made up of a > op, a couple assignments, and a plus op
- Let's see how that looks in AST

</Notes>

---

# Abstract Syntax Tree: It can grow!

<Img src={astIf} />

<Notes>

- AST scales infinitely and recursively
- so you can see if the If statement we have the > op, an assignment if true, and and assignment and a + op if false
- this can just keep growing until you've understood a whole program (but it wouldn't fit on a slide)
- then you can walk the tree and process it into instructions

</Notes>

---

<CodeSurfer>

```elixir title="AST Structs"
defmodule If do
  defstruct [:condition, :true_body, :false_body]

  @type t :: %__MODULE__{
          condition: Node.expression(),
          true_body: Node.statements(),
          false_body: Node.statements() | nil
        }
end

defmodule BinOp do
  defstruct [:op, :left, :right]

  @type t :: %__MODULE__{
          op: Node.bin_op(),
          left: Node.term_value(),
          right: Node.term_value()
        }
end
```

```diff 2
```

```diff 4:8
```

```diff 14:18
```

</CodeSurfer>

<Notes>

- Since this is Elixir and we have stucts and pattern matching, we have a great way of describing an AST
- each construct like If or an Operation gets a struct
- If has a condition which is an expression, a true body with is a statement, and an optional false body
- BinOp, which is any operation on two elements like + or >, has its op, a left and a right value
- As you can see for each struct I define a type that helps me remember what goes in each slot

</Notes>

---

# Parsing tokens into AST

<Notes>

- recursive like tokens
- instead of a flat list, return a tree
- for each token, look for a certain keyword like if
- parse until the thing is complete
- throw an error if there's an "unexpected token"

</Notes>

---

<CodeSurfer>

```elixir
defp parse_if!(tokens) do
  tokens = Tokens.eat!(tokens, :if)
  tokens = Tokens.eat!(tokens, "(")
  {expression, tokens} = Expression.parse_expression!(tokens)
  tokens = Tokens.eat!(tokens, ")")

  tokens = Tokens.eat!(tokens, "{")
  {statements, tokens} = parse_statements!(tokens)
  tokens = Tokens.eat!(tokens, "}")

  case Tokens.eat(tokens, :else) do
    {:ok, tokens} ->
      tokens = Tokens.eat!(tokens, "{")
      {else_statements, tokens} = parse_statements!(tokens)
      tokens = Tokens.eat!(tokens, "}")

      node = %Node.If{condition: expression, true_body: statements, false_body: else_statements}
      {node, tokens}

    {:error, _} ->
      node = %Node.If{condition: expression, true_body: statements}
      {node, tokens}
  end
end
```

```diff 2
```

```diff 3:5
```

```diff 17:18
```

</CodeSurfer>

<Notes>

- A key function is "eat", which looks for a token like if or a brace, and throws if its not there
- recursively parse other things like statements
- eventually construct an AST node
- Every eat and parse consumes some tokens and returns the ones it didn't use
- once all the tokens are used up, we're done!

</Notes>

---


<CodeSurfer>

```elixir
def compile(%Node.If{condition: condition, true_body: true_body, false_body: false_body}, table)
def compile(%Node.BinOp{op: op, left: left, right: right}, table)
def compile(%Node.VarName{name: name}, table)
def compile(%Node.BinOp{op: op, left: left, right: right}, table)
```

</CodeSurfer>

<Notes>

- finally once we have an AST, we can recursively walk the tree, and compile each node.
- so the compiler needs to know how to turn an if, an op, etc. into VM code
- if this was elixir, this is also the point where we could run macros on the AST to transform it before we compiled it!
- And if this was an interpreted language, everything up to now would have been the same. But instead of transforming to VM code, we could simply execute the instructions

</Notes>

---

# Takeaways

- Elixir is a good general purpose language!
- Tokenizers are simple and useful
- Data structures and recursion FTW

<Notes>

- There's a lot more, with symbol tables and error handling, but hopefully that's a nice taste

</Notes>

---

# Thanks!

---

# Elixir CLI tool

- `mix run compiler.exs path/to/files`
- `mix run compiler path/to/files`
- `mix escript.build && ./Compiler path/to/files`

<Notes>

- To start with, I thought it'd be interesting to see how to even set up a command line program with elixir
- There are a couple basic ways of setting running Elixir code as a cli script
- first you can just write an exs script file and run it with mix run
- you could also set up a mix task instead of just writing an arbitrary file
- or you can configure, compile, and run an escript. Escripts are cool because they're executables.
- As long as you have Erlang installed on your computer, you can run the compiled escript

</Notes>

---

<CodeSurfer>

```elixir title="compiler.exs"
alias Compiler

[filename] = System.argv()

File.cwd!()
|> Path.join(filename)
|> Path.expand()
|> Compiler.run()
```

```diff 1

```

```diff 3

```

```diff 5:7

```

```diff 8

```

</CodeSurfer>

<Notes>

- I ended up just going with an exs file for simplicity
- First I alias my main app. As long as I run this with mix run, that'll be available and compiled
- Get an argument from the command line for the directory to compile
- and makes that an absolute path
- and runs the compiler

</Notes>
